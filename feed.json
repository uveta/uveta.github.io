{
    "version": "https://jsonfeed.org/version/1",
    "title": "Uveta's blog",
    "description": "Uveta's blog about all things Azure",
    "home_page_url": "https://www.uveta.io",
    "items": [
        {
            "id": "https://www.uveta.io/categories/blog/unclutter-startup-cs/",
            "url": "https://www.uveta.io/categories/blog/unclutter-startup-cs/",
            "title": "Unclutter Startup.cs",
            "date_published": "2021-12-18T14:00:09.000Z",
            "content_html": "<html><head></head><body><img src=\"/categories/blog/unclutter-startup-cs/calendar.jpg\" class=\"\" title=\"Advent calendar\">\n\n<p>Configuring service container and setting up request pipeline in ASP.NET Core can eat up a lot of lines of code, especially for more complex projects. A well-established way of doing this is using <em>Startup.cs</em> and its <code>ConfigureServices()</code> and <code>Configure()</code> methods. Although complete application setup can be packed into a single type, we must not forget about Single-responsibility principle. I wanted to show you a way to prevent startup from growing uncontrollably, by keeping different concerns separate from each other.</p>\n<p>One disclaimer though. ASP.NET Core 6 has rolled in and removed the need of having <em>Startup.cs</em> altogether. Despite that fact, I am sure the ideas presented in this post will be relevant, even in the new era.</p>\n<span id=\"more\"></span>\n\n<p><em>This post is part of <a href=\"https://www.csadvent.christmas/\">C# Advent Calendar 2021</a>. Cheers to <a href=\"https://twitter.com/mgroves\">Matthew D. Groves</a> for letting me participate!</em></p>\n<h2 id=\"Basic-principles\"><a href=\"#Basic-principles\" class=\"headerlink\" title=\"Basic principles\"></a>Basic principles</h2><p>We will apply two .NET features: <a href=\"https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/options\">Options pattern</a> and <a href=\"https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/extension-methods\">Extension methods</a>. Similar to how ASP.NET Core uses plugin architecture, we will utilize these features to separate concerns and leave heavy lifting to dependency injection container.</p>\n<p>One design standard, to keep in mind, is that almost all parts of ASP.NET Core are configured via <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.options.ioptions-1\">IOptions<toptions></toptions></a> pattern. And, since all <code>IOptions&lt;TOptions&gt;</code> instances are part of service container, we can use <a href=\"https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/options#use-di-services-to-configure-options\">IConfigureOptions<toptions></toptions></a> or <a href=\"https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/options#options-post-configuration\">IPostConfigureOptions<toptions></toptions></a> to override any one of them.</p>\n<h2 id=\"MVC\"><a href=\"#MVC\" class=\"headerlink\" title=\"MVC\"></a>MVC</h2><p>Whether you are using Controllers only, or including Views or Razor Pages, MVC setup is more or less the same. The goal is to call <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.mvcservicecollectionextensions.addcontrollers\">AddControllers()</a>, <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.mvcservicecollectionextensions.addcontrollerswithviews\">AddControllersWithViews()</a> or <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.mvcservicecollectionextensions.addrazorpages\">AddRazorPages()</a>, based on your scenario, and define configuration for <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.mvc.mvcoptions\">MvcOptions</a>, and possibly <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.mvc.razorpages.razorpagesoptions\">RazorPagesOptions</a>. If you are using <a href=\"https://docs.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializer\">System.Text.Json</a> or <a href=\"https://www.nuget.org/packages/Microsoft.AspNetCore.Mvc.NewtonsoftJson\">Newtonsoft Json.NET</a> for model serialization, you could also configure them in a similar manner. Whole setup would look like this:</p>\n<figure class=\"highlight csharp hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">MvcExtensions</span></span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> IServiceCollection <span class=\"hljs-title\">ConfigureMvc</span>(<span class=\"hljs-params\"><span class=\"hljs-keyword\">this</span> IServiceCollection services</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        services.AddControllers().AddNewtonsoftJson();</span><br><span class=\"line\">        services.AddSingleton&lt;IConfigureOptions&lt;MvcOptions&gt;, ConfigureMvcOptions&gt;();</span><br><span class=\"line\">        services.AddSingleton&lt;IConfigureOptions&lt;MvcNewtonsoftJsonOptions&gt;, ConfigureNewtonsoftOptions&gt;();</span><br><span class=\"line\">        <span class=\"hljs-keyword\">return</span> services;</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ConfigureMvcOptions</span> : <span class=\"hljs-title\">IConfigureOptions</span>&lt;<span class=\"hljs-title\">MvcOptions</span>&gt;</span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">Configure</span>(<span class=\"hljs-params\">MvcOptions options</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        options.SuppressAsyncSuffixInActionNames = <span class=\"hljs-literal\">true</span>;</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ConfigureNewtonsoftOptions</span> : <span class=\"hljs-title\">IConfigureOptions</span>&lt;<span class=\"hljs-title\">MvcNewtonsoftJsonOptions</span>&gt;</span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">Configure</span>(<span class=\"hljs-params\">MvcNewtonsoftJsonOptions options</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        options.SerializerSettings.Converters.Add(<span class=\"hljs-keyword\">new</span> StringEnumConverter());</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"Authentication\"><a href=\"#Authentication\" class=\"headerlink\" title=\"Authentication\"></a>Authentication</h2><p>Completely driving authentication by configuration is difficult. You probably need to know what type of authentication your application uses in advance. Good news is that, once baseline is established, you can use above mentioned technique to configure individual parts. For example, you would use <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.authentication.cookies.cookieauthenticationoptions\">CookieAuthenticationOptions</a> to configure cookies, and <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.authentication.jwtbearer.jwtbeareroptions\">JwtBearerOptions</a> for token based authentication. Extension and individual configuration options, including an example of injecting IConfiguration into one of them, would look like this:</p>\n<figure class=\"highlight csharp hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">AuthenticationExtensions</span></span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> IServiceCollection <span class=\"hljs-title\">ConfigureAuthentication</span>(<span class=\"hljs-params\"><span class=\"hljs-keyword\">this</span> IServiceCollection services</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        services.AddAuthentication().AddCookie().AddJwtBearer();</span><br><span class=\"line\">        services.AddSingleton&lt;IConfigureOptions&lt;AuthenticationOptions&gt;, ConfigureAuthenticationOptions&gt;();</span><br><span class=\"line\">        services.AddSingleton&lt;IConfigureOptions&lt;CookieAuthenticationOptions&gt;, ConfigureCookieAuthenticationOptions&gt;();</span><br><span class=\"line\">        services.AddSingleton&lt;IConfigureOptions&lt;JwtBearerOptions&gt;, ConfigureJwtBearerOptions&gt;();</span><br><span class=\"line\">        <span class=\"hljs-keyword\">return</span> services;</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ConfigureAuthenticationOptions</span> : <span class=\"hljs-title\">IConfigureOptions</span>&lt;<span class=\"hljs-title\">AuthenticationOptions</span>&gt;</span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">Configure</span>(<span class=\"hljs-params\">AuthenticationOptions options</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        options.DefaultAuthenticateScheme = JwtBearerDefaults.AuthenticationScheme;</span><br><span class=\"line\">        options.DefaultChallengeScheme = JwtBearerDefaults.AuthenticationScheme;</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ConfigureCookieAuthenticationOptions</span> : <span class=\"hljs-title\">IConfigureOptions</span>&lt;<span class=\"hljs-title\">CookieAuthenticationOptions</span>&gt;</span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">Configure</span>(<span class=\"hljs-params\">CookieAuthenticationOptions options</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        options.ExpireTimeSpan = TimeSpan.FromHours(<span class=\"hljs-number\">1</span>);</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ConfigureJwtBearerOptions</span> : <span class=\"hljs-title\">IConfigureOptions</span>&lt;<span class=\"hljs-title\">JwtBearerOptions</span>&gt;</span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">readonly</span> IConfiguration _configuration;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-title\">ConfigureJwtBearerOptions</span>(<span class=\"hljs-params\">IConfiguration configuration</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        _configuration = configuration;</span><br><span class=\"line\">    }</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">Configure</span>(<span class=\"hljs-params\">JwtBearerOptions options</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        options.Authority = _configuration.GetValue&lt;<span class=\"hljs-built_in\">string</span>&gt;(<span class=\"hljs-string\">\"jwt:authority\"</span>);</span><br><span class=\"line\">        options.RequireHttpsMetadata = <span class=\"hljs-literal\">false</span>;</span><br><span class=\"line\">        options.IncludeErrorDetails = <span class=\"hljs-literal\">true</span>;</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"Authorization\"><a href=\"#Authorization\" class=\"headerlink\" title=\"Authorization\"></a>Authorization</h2><p>Configuring authorization can get quite tedious, if number or complexity of policies increases. Luckily, setup process is pretty straightforward, as the only concern is injecting configuration via <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.authorization.authorizationoptions\">AuthorizationOptions</a> type.</p>\n<figure class=\"highlight csharp hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">AuthorizationExtensions</span></span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> IServiceCollection <span class=\"hljs-title\">ConfigureAuthorization</span>(<span class=\"hljs-params\"><span class=\"hljs-keyword\">this</span> IServiceCollection services</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        services.AddAuthorization();</span><br><span class=\"line\">        services.AddSingleton&lt;IConfigureOptions&lt;AuthorizationOptions&gt;, ConfigureAuthorizationOptions&gt;();</span><br><span class=\"line\">        <span class=\"hljs-keyword\">return</span> services;</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ConfigureAuthorizationOptions</span> : <span class=\"hljs-title\">IConfigureOptions</span>&lt;<span class=\"hljs-title\">AuthorizationOptions</span>&gt;</span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">Configure</span>(<span class=\"hljs-params\">AuthorizationOptions options</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        options.DefaultPolicy = <span class=\"hljs-keyword\">new</span> AuthorizationPolicyBuilder().RequireAuthenticatedUser().Build();</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"OpenAPI\"><a href=\"#OpenAPI\" class=\"headerlink\" title=\"OpenAPI\"></a>OpenAPI</h2><p>If you care about your REST API consumers, you are publishing service description, using OpenAPI specification. And, since we are talking about ASP.NET Core, you are probably using awesome <a href=\"https://www.nuget.org/packages/Swashbuckle.AspNetCore\">Swashbuckle</a> package. As with previously mentioned framework parts, this extension was designed on same principles, and can be setup in a similar fashion. Whether its generating definition file using <code>SwaggerGenOptions</code>, or adjusting swagger user interface via <code>SwaggerUIOptions</code>, everything can be broken down and put into separate types.</p>\n<figure class=\"highlight csharp hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">OpenApiExtensions</span></span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> IServiceCollection <span class=\"hljs-title\">ConfigureOpenApi</span>(<span class=\"hljs-params\"><span class=\"hljs-keyword\">this</span> IServiceCollection services</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        services.AddSwaggerGen();</span><br><span class=\"line\">        services.AddSwaggerGenNewtonsoftSupport();</span><br><span class=\"line\">        services.AddSingleton&lt;IConfigureOptions&lt;SwaggerGenOptions&gt;, ConfigureSwaggerGenOptions&gt;();</span><br><span class=\"line\">        services.AddSingleton&lt;IConfigureOptions&lt;SwaggerOptions&gt;, ConfigureSwaggerOptions&gt;();</span><br><span class=\"line\">        services.AddSingleton&lt;IConfigureOptions&lt;SwaggerUIOptions&gt;, ConfigureSwaggerUiOptions&gt;();</span><br><span class=\"line\">        <span class=\"hljs-keyword\">return</span> services;</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ConfigureSwaggerGenOptions</span> : <span class=\"hljs-title\">IConfigureOptions</span>&lt;<span class=\"hljs-title\">SwaggerGenOptions</span>&gt;</span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">Configure</span>(<span class=\"hljs-params\">SwaggerGenOptions options</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        options.SwaggerDoc(<span class=\"hljs-string\">\"v1\"</span>, <span class=\"hljs-keyword\">new</span> OpenApiInfo { Title = <span class=\"hljs-string\">\"Demo\"</span>, Version = <span class=\"hljs-string\">\"v1\"</span> });</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ConfigureSwaggerOptions</span> : <span class=\"hljs-title\">IConfigureOptions</span>&lt;<span class=\"hljs-title\">SwaggerOptions</span>&gt;</span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">Configure</span>(<span class=\"hljs-params\">SwaggerOptions options</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        options.RouteTemplate = <span class=\"hljs-string\">\"swagger/{documentName}/swagger.json\"</span>;</span><br><span class=\"line\">        options.PreSerializeFilters.Add((swaggerDoc, httpReq) =&gt;</span><br><span class=\"line\">        {</span><br><span class=\"line\">            swaggerDoc.Servers = <span class=\"hljs-keyword\">new</span>[] {</span><br><span class=\"line\">                <span class=\"hljs-keyword\">new</span> OpenApiServer {</span><br><span class=\"line\">                    Url = <span class=\"hljs-string\">$\"<span class=\"hljs-subst\">{httpReq.Scheme}</span>://<span class=\"hljs-subst\">{httpReq.Host.Value}</span><span class=\"hljs-subst\">{httpReq.PathBase}</span>\"</span>,</span><br><span class=\"line\">                    Description = <span class=\"hljs-string\">\"Default\"</span></span><br><span class=\"line\">                }</span><br><span class=\"line\">            };</span><br><span class=\"line\">        });</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ConfigureSwaggerUiOptions</span> : <span class=\"hljs-title\">IConfigureOptions</span>&lt;<span class=\"hljs-title\">SwaggerUIOptions</span>&gt;</span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">Configure</span>(<span class=\"hljs-params\">SwaggerUIOptions options</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        options.SwaggerEndpoint(<span class=\"hljs-string\">\"/swagger/v1/swagger.json\"</span>, <span class=\"hljs-string\">\"Demo v1\"</span>);</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"Application-Insights\"><a href=\"#Application-Insights\" class=\"headerlink\" title=\"Application Insights\"></a>Application Insights</h2><p>How about some Azure extensions? Most of the time you will not even need them, as ASP.NET Core seamlessly integrates with most of Azure resources. However, one particular extension I recommend using are <a href=\"https://www.nuget.org/packages/Microsoft.ApplicationInsights.AspNetCore\">Application Insights</a>. You want to have application telemetry under control, and this package allows you to fine tune metrics and data that will be ingested by Azure. From setup point of view, there is nothing surprising:</p>\n<figure class=\"highlight csharp hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">TelemetryExtensions</span></span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> IServiceCollection <span class=\"hljs-title\">ConfigureTelemetry</span>(<span class=\"hljs-params\"><span class=\"hljs-keyword\">this</span> IServiceCollection services</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        services.AddApplicationInsightsTelemetry();</span><br><span class=\"line\">        services.AddSingleton&lt;IConfigureOptions&lt;ApplicationInsightsServiceOptions&gt;, ConfigureApplicationInsights&gt;();</span><br><span class=\"line\">        <span class=\"hljs-keyword\">return</span> services;</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ConfigureApplicationInsights</span> : <span class=\"hljs-title\">IConfigureOptions</span>&lt;<span class=\"hljs-title\">ApplicationInsightsServiceOptions</span>&gt;</span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">Configure</span>(<span class=\"hljs-params\">ApplicationInsightsServiceOptions options</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        options.EnableHeartbeat = <span class=\"hljs-literal\">true</span>;</span><br><span class=\"line\">        options.EnableAppServicesHeartbeatTelemetryModule = <span class=\"hljs-literal\">true</span>;</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"Extras\"><a href=\"#Extras\" class=\"headerlink\" title=\"Extras\"></a>Extras</h2><p>You’ve probably gotten the gist of it by now; use extension methods to extract service definitions, and options to do actual service configuration. For completeness, let me give you the rest of commonly used ASP.NET Core features, including types used for configuration.</p>\n<ul>\n<li>Default files middleware via <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.builder.defaultfilesextensions.usedefaultfiles\">UseDefaultFiles()</a> - <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.builder.defaultfilesoptions\">DefaultFilesOptions</a></li>\n<li>Static files middleware via <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.builder.staticfileextensions.usestaticfiles\">UseStaticFiles()</a> - <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.builder.staticfileoptions\">StaticFileOptions</a></li>\n<li>Cross-Origin Resource Sharing via <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.corsservicecollectionextensions.addcors\">AddCors()</a> - <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.cors.infrastructure.corsoptions?view=aspnetcore-6.0\">CorsOptions</a></li>\n<li>API Versioning services via <a href=\"https://www.nuget.org/packages/Microsoft.AspNetCore.Mvc.Versioning\">AddApiVersioning() and AddVersionedApiExplorer()</a> - <a href=\"https://github.com/dotnet/aspnet-api-versioning/blob/master/src/Microsoft.AspNetCore.Mvc.Versioning.ApiExplorer/ApiExplorerOptions.cs\">ApiExplorerOptions</a> and <a href=\"https://github.com/dotnet/aspnet-api-versioning/blob/master/src/Common/Versioning/ApiVersioningOptions.cs\">ApiVersioningOptions</a></li>\n</ul>\n<h2 id=\"Application-code\"><a href=\"#Application-code\" class=\"headerlink\" title=\"Application code\"></a>Application code</h2><p>Last but not least, what about your own application code? I highly recommend following the same principles, in order to avoid having application setup in a single place. If you are using clean architecture, and have your code decoupled into layers, initialization could be as simple as:</p>\n<figure class=\"highlight csharp hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ApplicationExtensions</span></span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> IServiceCollection <span class=\"hljs-title\">ConfigureApplication</span>(<span class=\"hljs-params\"><span class=\"hljs-keyword\">this</span> IServiceCollection services</span>)</span></span><br><span class=\"line\">    {</span><br><span class=\"line\">        services</span><br><span class=\"line\">            .AddDomain()</span><br><span class=\"line\">            .AddApplicationServices()</span><br><span class=\"line\">            .AddRepositories()</span><br><span class=\"line\">            .AddIntegration();</span><br><span class=\"line\">        <span class=\"hljs-keyword\">return</span> services;</span><br><span class=\"line\">    }</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>I have shown you one neat little trick that I use all the time, when setting up any kind of application. It is important to remember Single-responsibility principle, even for this type of code. Having <em>Startup.cs</em> consisting of several hundreds, or even thousands lines, is nothing unheard of. And, sadly, is an obvious code smell.</p>\n<p>All code shown in this post was published to <a href=\"https://github.com/uveta/demo-unclutter-startup\">GitHub</a>, as a single ASP.NET Core 6 project.</p>\n</body></html>",
            "tags": [
                "azure",
                "advanced",
                "dotnet"
            ]
        },
        {
            "id": "https://www.uveta.io/categories/blog/asynchronous-job-pattern-the-asp-net-core-mvc-way/",
            "url": "https://www.uveta.io/categories/blog/asynchronous-job-pattern-the-asp-net-core-mvc-way/",
            "title": "Asynchronous Job Pattern - The ASP.NET Core MVC Way",
            "date_published": "2020-12-21T20:33:44.000Z",
            "content_html": "<html><head></head><body><img src=\"/categories/blog/asynchronous-job-pattern-the-asp-net-core-mvc-way/calendar.jpg\" class=\"\" title=\"Advent calendar\">\n\n<p>Let me present a pattern we used to solve a problem haunting our enterprise application for ages. It was initially designed to handle long running operations, using <a href=\"http://restalk-patterns.org/long-running-operation-polling.html\">RESTful approach</a>, but we soon realized it could be used in many other ways. As it generalizes the system of submitting requests and obtaining responses, it can easily be adapted to different business processes, while keeping unified client interface.</p>\n<span id=\"more\"></span>\n\n<p><em>This post is part of <a href=\"https://www.csadvent.christmas/\">C# Advent Calendar 2020</a>. Cheers to <a href=\"https://twitter.com/mgroves\">Matthew D. Groves</a> for letting me participate!</em></p>\n<h2 id=\"Building-blocks\"><a href=\"#Building-blocks\" class=\"headerlink\" title=\"Building blocks\"></a>Building blocks</h2><p>From a <em>client</em> perspective, the pattern usage is pretty simple: it submits a <em>job</em> for processing to an <em>endpoint</em>; <em>job</em> status is polled until processing is finished; if status was successful, client uses <em>endpoint</em> to obtain output.</p>\n<p>On server side, several components are required to achieve such functionality. Lets take a look at the big picture and define individual pattern pieces.</p>\n<h3 id=\"Job\"><a href=\"#Job\" class=\"headerlink\" title=\"Job\"></a>Job</h3><p>A <em>job</em> is a principal entity, representing <em>client</em> intent processed by a designated <em>worker</em>. It is composed of:</p>\n<ul>\n<li><strong>Header</strong>, containing job metadata such as unique identifier, current status, time of creation/start/finish, potential issues as well as estimated time of completion</li>\n<li><strong>Input parameters</strong></li>\n<li><strong>Output values</strong></li>\n</ul>\n<h3 id=\"Worker\"><a href=\"#Worker\" class=\"headerlink\" title=\"Worker\"></a>Worker</h3><p>Component that does heavy lifting. Main responsibility is actual processing, as each <em>worker</em> is able to handle specific <em>job</em> type. In simple terms, we can describe it as a function accepting input parameters and returning either <em>job</em> output or an error.</p>\n<h3 id=\"Endpoint\"><a href=\"#Endpoint\" class=\"headerlink\" title=\"Endpoint\"></a>Endpoint</h3><p>Serves as an entry-point for <em>clients</em>. After creating a job, <em>client</em> should be able to obtain <em>job</em> status at any point in time, as well as output after processing is finished. <em>Endpoint</em> should also allow <em>client</em> to cancel and clean-up a <em>job</em>. Hence, it needs to provide following services:</p>\n<ul>\n<li>Create <em>job</em></li>\n<li>Get <em>job</em> status</li>\n<li>Get <em>job</em> output</li>\n<li>Delete <em>job</em></li>\n</ul>\n<h3 id=\"Job-Repository-and-Queue\"><a href=\"#Job-Repository-and-Queue\" class=\"headerlink\" title=\"Job Repository and Queue\"></a>Job Repository and Queue</h3><p>A <em>repository</em> will be used to store all <em>jobs</em>, which would allow both <em>endpoint</em> and <em>worker</em> to read and update <em>job</em> state. For now, let’s consider <em>repository</em> an abstraction, as concrete implementation and storage technology may vary, depending on usage scenario.</p>\n<p>Binding between an <em>endpoint</em> and a <em>worker</em> would be achieved using a <em>job queue</em> concept. It has to provide a <em>producer</em> and a <em>consumer</em>, depending on the component using <em>queue</em> services. Similar to how <em>repository</em> was defined, implementation may range from memory one to a hyper-scale message broker. </p>\n<p>Final pattern architecture is depicted in the diagram bellow. As all core components are defined, we should move on to implementation using APS.NET Core.</p>\n<p><img src=\"architecture.png\" alt=\"Job pattern architecture\"></p>\n<h2 id=\"ASP-NET-Core-implementation\"><a href=\"#ASP-NET-Core-implementation\" class=\"headerlink\" title=\"ASP.NET Core implementation\"></a>ASP.NET Core implementation</h2><h3 id=\"Implementation-considerations\"><a href=\"#Implementation-considerations\" class=\"headerlink\" title=\"Implementation considerations\"></a>Implementation considerations</h3><p>In order to make the implementation as universal as possible, we need to limit <em>job</em> inputs and outputs to one of each. If multiple values are expected, they could be provided via a custom model. <code>JobExecutionResult</code> will serve as a wrapper for output value, containing result of <em>worker</em> execution and any possible issues. If we define them as types <code>TInput</code> and <code>TOutput</code>, our <em>worker</em> and <em>endpoint</em> could look something like this:</p>\n<script src=\"https://gist.github.com/uveta/85943b7354871239058c4b45ffca8ee9.js\"></script>\n<script src=\"https://gist.github.com/uveta/9ebe4d6514c8bf6d22dca908eeeb0c04.js\"></script>\n\n<p>As <em>endpoint</em> is user independent concept, it will be up to pattern to provide the implementation. On the other hand, <em>worker</em> is responsible for executing custom actions, hence it’s implementation has to be provided by the pattern user. This reasoning will come into play during design, as we would like to provide plugin architecture for individual pattern components. This will allow utilizing only building blocks required for given scenario, while the user would provide implementation of required and customizable parts.</p>\n<h3 id=\"Plugging-in-worker-implementation\"><a href=\"#Plugging-in-worker-implementation\" class=\"headerlink\" title=\"Plugging in worker implementation\"></a>Plugging in worker implementation</h3><p><em>Worker</em> flow is straightforward: it should use <em>queue consumer</em> to listen for incoming <em>jobs</em>; whenever one is received, it should process it and update <em>job</em> status and output via <em>repository</em>; then it waits for next one and repeats previous steps. This cycle is supposed to run for the whole application lifetime, as new <em>jobs</em> can arrive at any time. A natural solution to implement such functionality are <a href=\"https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services\">hosted services</a>. In our case, we could extract all common code (starting <em>queue consumer</em>, input/output serialization and <em>job</em> update) to a <code>WorkerInvoker&lt;TWorker&gt;</code> hosted service, bound to specific <em>worker</em> by it generic type <code>TWorker</code>.</p>\n<p>Adding <code>TWorker</code> type to DI container has multiple benefits. On one side, it can be injected into <code>WorkerInvoker&lt;TWorker&gt;</code>, removing the need to create it manually. On the other hand, it allows developers of <code>TWorker</code> to freely inject business services into it.</p>\n<h3 id=\"Exposing-endpoints\"><a href=\"#Exposing-endpoints\" class=\"headerlink\" title=\"Exposing endpoints\"></a>Exposing endpoints</h3><p>Since controllers are used as primary entry point into MVC applications, they are an obvious choice for coupling with <em>endpoints</em>. In this case, <a href=\"http://restalk-patterns.org/long-running-operation-polling.html\">initial description</a> should be followed to the letter, as we are in domain of HTTP REST operations. Hence, controllers should include following routes:</p>\n<ul>\n<li><strong>POST <em>/jobs</em></strong>: allows creating new jobs; responds with status <em>202 (Accepted)</em>, containing <em>job</em> resource <em>URL</em></li>\n<li><strong>GET <em>/jobs/{jobId}</em></strong>: resource <em>URL</em> can be used for polling <em>job</em> status, while in progress; when processing is finished, use <em>303 (See Other)</em> redirect to provide client with an output resource <em>URL</em></li>\n<li><strong>GET <em>/jobs/{jobId}/output</em></strong>: output resource <em>URL</em>; should return <em>200 (OK)</em> result containing output value, after <em>job</em> processing finishes; returns <em>404 (NotFound)</em> error otherwise</li>\n<li><strong>DELETE <em>/jobs/{jobId}</em></strong>: disposes of any reserved resources; client should call it after polling finishes and output is obtained; if not done by client, server should clean up old <em>jobs</em> automatically</li>\n</ul>\n<p>The burden of creating a controller should not fall on the user; it is the responsibility of the pattern itself, since each route functionality is known in advance. For this purpose we could implement a generic <code>JobsController&lt;TEndpoint&gt;</code>, which would be bound to specific <em>endpoint</em> via its type parameter <code>TEndpoint</code>.</p>\n<p>As multiple <em>endpoints</em> per service have to be supported, MVC requires providing different underlying type for each controller. This is not possible with our idea of using a generic one, as changing generic’s type parameter does not change overall generic type. Instead, we should create individual controller type from base generic dynamically, using a bit of <a href=\"https://docs.microsoft.com/en-us/dotnet/api/system.reflection.emit.typebuilder\">TypeBuilder</a> reflection magic. Generated types could then be added to MVC using custom <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.mvc.applicationparts.iapplicationparttypeprovider\">IApplicationPartTypeProvider</a>.</p>\n<h3 id=\"Few-words-on-repository-and-queue\"><a href=\"#Few-words-on-repository-and-queue\" class=\"headerlink\" title=\"Few words on repository and queue\"></a>Few words on repository and queue</h3><p>Following how we defined <em>job repository</em> and <em>queue</em>, respecting interfaces would be:</p>\n<script src=\"https://gist.github.com/uveta/44ca3dfbba05536e5091fbc353b611ec.js\"></script>\n<script src=\"https://gist.github.com/uveta/585866e8ae67e75d7c65eac9cccb6d0b.js\"></script>\n\n<p>The pattern has to supply default memory implementation for both of them. Although this should suffice for test and single-service usage, it completely falls flat in any advanced scenarios. Hence, replacing default implementations must be allowed via extensions.</p>\n<h3 id=\"Configuring-job-services\"><a href=\"#Configuring-job-services\" class=\"headerlink\" title=\"Configuring job services\"></a>Configuring job services</h3><p>We should follow principals ASP.NET Core was build upon and adopt a plugin architecture in order to configure our pattern services. I used <a href=\"https://github.com/uveta/extensions-jobs/tree/main/samples/MvcDemo\">a sample project</a> to demonstrate how such behavior could be achieved. The following example includes definition of one <em>endpoint</em> and its bound <em>worker</em>.</p>\n<script src=\"https://gist.github.com/uveta/777c12716df3015ebc67a651916bea23.js\"></script>\n\n<p>In this case, <code>PingRequest</code> and <code>PingResponse</code> correspond to input and output types. <code>PingWorker</code> represents a custom implementation of <code>IWorker</code>, supplied by user. Other components (<em>endpoint</em>, <em>repository</em> and <em>queue</em>) are provided by pattern and only configured here.</p>\n<h2 id=\"Usage-alternatives\"><a href=\"#Usage-alternatives\" class=\"headerlink\" title=\"Usage alternatives\"></a>Usage alternatives</h2><p>Proposed implementation is just one of many possible, as well as its usage. All building blocks are introduced as abstract concepts, which can be adapted for different scenarios than initially intended. For example, an <em>endpoint</em> could be utilized to issue an RPC call without knowing the address of remote service; client would use <em>endpoint</em> to create a new job, which would reach designated <em>worker</em> via queue, effectively removing the need of individual services knowing other ones even exist. Only constraint is imposed by specific business feature, having strictly defined input and output.</p>\n<p>Further improvements can be introduced on <em>workers</em> as well. In order to use them in a real-world scenarios, there has to be a possibility of configuring their maximum scaling and execution period limits. This feature will have to be supported by <em>queue</em> implementation, as <em>worker</em> is invoked based on actions triggered by <em>queue consumer</em>.</p>\n<p>Finally, default memory implementations of <em>queue</em> and <em>repository</em> are only good for <a href=\"https://github.com/uveta/extensions-jobs/tree/main/samples/MvcDemo\">demonstration purposes</a>. <em>Repository</em> should offer some form of permanent external storage, especially if usage in multi-service applications is considered. Same goes for <em>queue</em>, as the need for underlying message broker is evident in even simple production scenarios.</p>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>In this article I explained which set of problems did we solve using long running job pattern. We also saw one of the ways to implement it, using ASP.NET Core MVC. As a final observation, I described how inner pattern components can be used outside of MVC, in any system that wants to generalize request/response flow and reduce service coupling.</p>\n<p>Source code and samples can be found on <a href=\"https://github.com/uveta/extensions-jobs\">Github</a>. Individual packages have also been published to <a href=\"https://www.nuget.org/packages/Uveta.Extensions.Jobs/\">nuget.org</a>, in case you would like to try them in your own application.</p>\n</body></html>",
            "tags": [
                "advanced",
                "microservices",
                "dotnet"
            ]
        },
        {
            "id": "https://www.uveta.io/categories/blog/windows-vs-linux-appservice-whats-the-difference/",
            "url": "https://www.uveta.io/categories/blog/windows-vs-linux-appservice-whats-the-difference/",
            "title": "Windows vs Linux App Service - What is the Difference?",
            "date_published": "2020-11-29T19:00:10.000Z",
            "content_html": "<html><head></head><body><img src=\"/categories/blog/windows-vs-linux-appservice-whats-the-difference/windows_linux.png\" class=\"\" title=\"Windows and Linux logo\">\n\n<p>I always wanted to devote an article to Azure App Service, as it is my personal weapon of choice for hosting Web Apps. And what better topic to choose, than the one I always found official documentation severely lacking: describing feature difference between Windows and Linux platforms.</p>\n<span id=\"more\"></span>\n\n<h2 id=\"Why-App-Service\"><a href=\"#Why-App-Service\" class=\"headerlink\" title=\"Why App Service?\"></a>Why App Service?</h2><p>To me, App Service offers perfect balance between ease of deployment and features supported. Adding to its maturity is a rich set of tools and plugins, promoting work in almost any environment.</p>\n<p>A major decision, before even getting to deployment, is the choice of Windows or Linux platform. Without going deep into architectural details, I will try to explain main differences which should interest you as a consumer.</p>\n<h2 id=\"Which-App-Service-Plan-to-choose\"><a href=\"#Which-App-Service-Plan-to-choose\" class=\"headerlink\" title=\"Which App Service Plan to choose?\"></a>Which App Service Plan to choose?</h2><p>Platform on which App Service would be running is dictated by its App Service Plan. If underlying plan is running Windows, service will have to as well. Same goes for Linux. Hence, you cannot mix different platform services on a single plan.</p>\n<p>Furthermore, due to the limitations of underlying networking implementation, plans with different platforms cannot even be a part of the same resource group. You will need at least 2 resource groups if you want to support both Windows and Linux deployments.</p>\n<h2 id=\"Is-my-application-stack-supported\"><a href=\"#Is-my-application-stack-supported\" class=\"headerlink\" title=\"Is my application stack supported?\"></a>Is my application stack supported?</h2><p>App Service documentation states it can run applications written in following languages: .NET, .NET Core, Java, Node.js, Ruby, PHP and Python. However, depending on the platform, certain limitations are in place. Linux service is obviously unable to run older .NET applications, but only .NET Core, so Windows is the only alternative if using ASP.NET. On the other hand, Ruby is supported only on Linux service.</p>\n<p>Good news is that both platforms support running containers, allowing further customization of execution environment. If runtime is not among supported languages, it will have to be included in the deployment image.</p>\n<h2 id=\"Who-handles-incoming-web-requests\"><a href=\"#Who-handles-incoming-web-requests\" class=\"headerlink\" title=\"Who handles incoming web requests?\"></a>Who handles incoming web requests?</h2><p>Choice of platform also determines primary entry-point to the application. In case of Windows, Internet Information Services (IIS) is used, while Apache HTTP Server would be used on Linux. Since integration of IIS and App Service is far more mature, running under Linux imposes few limitations:</p>\n<ul>\n<li>Application will always run out of process, as opposed to in-process hosting. Even if using supported stack, i.e. .NET Core, it will still default to out of process hosting, under these circumstances. This can result in reduced throughput, especially if application is serving ample amounts of incoming requests.</li>\n<li>Custom path mappings are not available, forcing application hosting on root path only. There is, however, a possibility to provide up to 5 path mappings to external storage accounts, e.g. to serve static resources.</li>\n<li>Custom IIS features are clearly not supported. If IIS configuration file (web.config) is present, it will simply be ignored. This limits usage of IIS modules, such as application initialization.</li>\n</ul>\n<h2 id=\"What-do-I-do-when-things-go-wrong\"><a href=\"#What-do-I-do-when-things-go-wrong\" class=\"headerlink\" title=\"What do I do when things go wrong?\"></a>What do I do when things go wrong?</h2><p>Linux users will also have hard time diagnosing running applications. For example, when running a Windows service, setting up remote debugging via Visual Studio (Code) is trivial, as it can be enabled by simply flipping a switch in App Service settings. Although it is possible to use remote debugging on Linux, via SSH tunnel, the setup is not straightforward and not available off the shelf, as it is the case with Windows.</p>\n<p>Luckily, Linux App Service permits incoming SSH connection, which can be initiated from Azure Portal, as well as remotely, using preferred client. This opens a world of possibilities when trying to determine why running applications are not behaving optimally.</p>\n<h2 id=\"Which-App-Service-extensions-can-I-use\"><a href=\"#Which-App-Service-extensions-can-I-use\" class=\"headerlink\" title=\"Which App Service extensions can I use?\"></a>Which App Service extensions can I use?</h2><p>When talking about App Service extensions the situation is pretty clear: they are fully supported on Windows, and not supported at all on Linux. This can have implications if hosted application depends on any of them. For example, Azure Application Insights cannot be enabled from App Service, but application itself has to include Insights SDK. Instrumentation key can still be passed via App Service settings.</p>\n<p>WebJobs are another victim in this case. They cannot be operated independently of the application, at least not in the way they are created and ran on Windows service. Although Linux offers some alternatives, such as cron jobs, they have to be setup and monitored manually via SSH.</p>\n<h2 id=\"Any-final-words\"><a href=\"#Any-final-words\" class=\"headerlink\" title=\"Any final words?\"></a>Any final words?</h2><p>This article could have easily be named <em>“10 and more advantages of Windows over Linux App Service”</em>, but I decided to stick with my initial idea. It is obvious that Windows version is much more mature, offering a rich collection of additional features, while Linux is slowly catching up.</p>\n<p>There are however some situations where you should choose the less mature option. Linux is currently your only choice if you want to run Ruby applications out-of-the-box, not including custom container option. In case cost optimization is important, Linux is generally a better choice, as it does not come with any operating system license charges.</p>\n<p>I hope information in this article will make choosing your future App Service platform a bit more straightforward.</p>\n</body></html>",
            "tags": [
                "azure",
                "advanced"
            ]
        },
        {
            "id": "https://www.uveta.io/categories/blog/azure-functions-deep-dive/",
            "url": "https://www.uveta.io/categories/blog/azure-functions-deep-dive/",
            "title": "Azure Functions Deep Dive",
            "date_published": "2020-10-24T15:16:59.000Z",
            "content_html": "<html><head></head><body><img src=\"/categories/blog/azure-functions-deep-dive/banner.jpg\" class=\"\" title=\"Function in action\">\n\n<p>Ever wondered what happens under the hood of Azure Functions? How can your server code magically run without a server? How does it know when to scale and how much? How to adjust your application to run optimally as a function? I’ve got you covered.</p>\n<span id=\"more\"></span>\n\n<h2 id=\"How-did-it-all-start\"><a href=\"#How-did-it-all-start\" class=\"headerlink\" title=\"How did it all start\"></a>How did it all start</h2><p>In 2014 (ancient history!) Microsoft introduced WebJobs. As a part of their Azure Web Sites PAAS offering (later re-branded as Azure Web Apps), it allowed uses to run arbitrary application in Azure, be it a Windows executable, Powershell, bash script, or code written in .NET, Java, PHP, Python or JavaScript. Not only that, but it had built-in input and output bindings for various Azure resources, such as blob storage, queue or Service Bus. From the get-go, you could trigger your WebJob from all of these resources, and write to them, without having to handle communication yourself. Later extensions allowed jobs to be triggered by CRON timers and HTTP requests. Sounds familiar? This is how Azure WebJobs SDK came to be, which later served as a base platform for Azure Functions.</p>\n<p>Although they are still available as part of Web Apps (check <a href=\"https://docs.microsoft.com/en-us/azure/app-service/webjobs-create\">Web Jobs</a> blade on your App Service) and have their fair share of usage, Web Jobs have mostly been replaced with higher order resources, such as Function or Logic Apps.</p>\n<h2 id=\"Components\"><a href=\"#Components\" class=\"headerlink\" title=\"Components\"></a>Components</h2><p>As we established in the previous section, Azure WebJobs SDK is an essential piece of Function Apps. It is responsible for running custom application and provides bindings to external resources. Another part is, for completeness’ sake, the custom application itself, serving whatever purpose user sees fit. But we mustn’t forget about another, equally important component. The glue that ties it all together, the <a href=\"https://github.com/Azure/azure-functions-host\">Azure Functions Host</a>.</p>\n<h3 id=\"Functions-Host\"><a href=\"#Functions-Host\" class=\"headerlink\" title=\"Functions Host\"></a>Functions Host</h3><p>Functions Host is, in its core, a lightweight ASP.NET Core application running on top of Azure WebJobs SDK. It serves as a connector between custom application (executed by a trigger), all <em>function.json</em> files (containing individual functions metadata) and single <em>host.json</em> file (host configuration including logging, specific trigger options and various extension settings, common for all functions that are part of a single Function App).</p>\n<p>Custom application itself is discovered and managed by Functions Host, and executed via WebJobs SDK. Scaling, however, lies outside of responsibilities of Host instances. It is managed by an independent component - Scale Controller.</p>\n<h3 id=\"Scale-Controller\"><a href=\"#Scale-Controller\" class=\"headerlink\" title=\"Scale Controller\"></a>Scale Controller</h3><p>Just as Functions Host is responsible for handling and running individual functions, Scale Controller also plays a managerial role, but for Host instances themselves. It is in charge of creating and destroying individual Hosts, depending on the current workload. Scaling decisions are made based on metrics gathered from resources used as input triggers. Scale Controller is responsible for consuming these metrics and adjusting number of active Host instances.</p>\n<p>As an example, let us have a function triggering of an Azure Service Bus. Scale Controller would have to monitor current number of active messages, as well as maximum message throughput obtained from configuration. In case active message count starts rapidly rising, it will spin up new instances to handle increased load. As number of messages decreases, so will inactive instances be destroyed by Scale Controller.</p>\n<h2 id=\"Deployment-and-Hosting\"><a href=\"#Deployment-and-Hosting\" class=\"headerlink\" title=\"Deployment and Hosting\"></a>Deployment and Hosting</h2><p>I have already mentioned that Function Apps support plethora of programming languages and scripts, e.g .NET, Java, JavaScript, Powershell and Bash, and the list goes on. Even containers are supported, as custom Docker images can be hosted in Function Apps as well.</p>\n<p>On the other hand, multiple hosting plan scenarios are possible: Consumption, running functions only when required; Dedicated, using deployed App Service Plans to run functions alongside existing App Services; and finally Premium, using dedicated elastic App Service Plans to offer unparalleled performance, response time and scaling capabilities. Each of them has its strengths and weaknesses, and I encourage you to go through official documentation before considering function usage.</p>\n<p>Overabundance of supported application and hosting models sadly has its negative sides - not all combinations are supported and not all of them operate effectively together. When other factors are taken into account, such as in-process and out-of process hosting, supported runtimes and operating systems, as well as minimum performance requirements, available options can seriously get limited. I would recommend reading comparison of <a href=\"https://docs.microsoft.com/en-us/azure/azure-functions/functions-scale\">Azure Functions hosting plans</a> before getting seriously involved. The article also contains well-organized support tables for each of hosting options.</p>\n<h2 id=\"Tips-and-trick\"><a href=\"#Tips-and-trick\" class=\"headerlink\" title=\"Tips and trick\"></a>Tips and trick</h2><p>I could have named this section ‘Azure Functions Best Practices’, but Microsoft already <a href=\"https://docs.microsoft.com/en-us/azure/azure-functions/functions-best-practices\">beat me to it!</a> Instead of repeating the same conventions you’ve heard over and over again, I wanted to focus on something different. Specifically, on certain points that I became aware through my experience working with functions. Information following will help you better understand what and what functions can’t be used for, how to use them in a more efficient way and what to do if it all goes haywire.</p>\n<h3 id=\"Logging\"><a href=\"#Logging\" class=\"headerlink\" title=\"Logging\"></a>Logging</h3><p>Unless you added your own custom logging infrastructure, there is a good chance that all telemetry, requests and traces are consumed by Application Insights associated with your Function App. I will not go into detail on how to query this data, but will leave you with a <a href=\"https://docs.microsoft.com/en-us/azure/azure-functions/configure-monitoring\">handy explanation</a> on how it is organized and how to locate individual function components logs.</p>\n<p>Default logging configuration is pretty great, and you would not need to modify it 99.99% of the time. But there is still that 00.01% that will eventually come up, be it during development or trying to solve an issue in production. As all .NET Core applications, functions use structured logging as well, which can be adjusted either by modifying <em>host.json</em> configuration directly, or via <a href=\"https://docs.microsoft.com/en-us/azure/azure-functions/functions-host-json#override-hostjson-values\">application settings</a>. The most interesting categories that support modifying logging levels are:</p>\n<ul>\n<li>Function - includes execution start/stop time, dependencies tracking, thrown exceptions, as well as any logs from custom application, in case the code is consuming provided ILogger instance</li>\n<li>Host - contains function invocation count, success rate and duration telemetries; invocation success and failures are also logged</li>\n<li>Microsoft - in case custom application was written in .NET, handles logs coming from .NET components used, e.g. HttpClient, Hosting etc.</li>\n<li>Worker - if running non .NET application, its’ console output would be written using this category</li>\n</ul>\n<p>Reading the list, you must have thought: “Cool, so I can monitor individual function components. But wait a minute… Where is the Scale Controller?!”. No worries, Microsoft is on the case. Gathering logs from <a href=\"https://docs.microsoft.com/en-us/azure/azure-functions/functions-monitoring?tabs=cmd#scale-controller-logs\">Scale Controller</a> is available, but still as a preview feature. For now, it can be configured exclusively using application settings.</p>\n<h3 id=\"Function-sandbox\"><a href=\"#Function-sandbox\" class=\"headerlink\" title=\"Function sandbox\"></a>Function sandbox</h3><p>It goes without saying, but don’t expect your functions to be running on bare metal. Whats more, they are not even hosted on dedicated Virtual Machine. Instead, Function Apps are constrained to what is called an <a href=\"https://github.com/projectkudu/kudu/wiki/Azure-Web-App-sandbox\">Azure Web App sandbox</a>, which, by the way, is the same environment running App Services. The sandbox imposes many limitations, but most important ones, from the point of view of Function App developer, are:</p>\n<ul>\n<li>no access to Windows shared components - meaning no writing to registry, no service management using SCM and no access to processes outside of sandbox. One more important feature missing is usage of GDI32 graphics subsystem, which is still, sadly, used by most PDF generator tools.</li>\n<li>no disk access - generally, you are not able to read/write to disk even if the target path exists. There are however two exceptions: you can either use storage shared by all sandboxes (/home) or local sandbox storage (/local). Note, however, that local storage is deleted when host instance is terminated.</li>\n<li>limited network features - custom application is allowed to listen on any incoming port, but that port will only be available within the sandbox and not to external clients. It cannot use localhost or 127.0.0.1 address to open connection to ports it did not open itself. On the other side, some of the outgoing ports are restricted, namely 137, 138, 139 and 445.</li>\n</ul>\n<h3 id=\"Function-performance-counter-limits\"><a href=\"#Function-performance-counter-limits\" class=\"headerlink\" title=\"Function performance counter limits\"></a>Function performance counter limits</h3><p>These limitations are essentially imposed by the Web App sandbox environment as well. Unlike the ones listed in the previous chapter, these ones can be circumvented if your application is properly adapted to run in Function App. Please note that they apply only when hosting on Consumption Plan; if you are hosting using Dedicated or Premium Plans, limitations will depend on VM size used. All the limitations are tracked by <a href=\"https://github.com/Azure/azure-functions-host/wiki/Host-Health-Monitor\">Host Health Monitor</a>, which will start issuing warnings once function approaches or breaks any of the limits. Keep an eye out on Application Insights, where all function failures are logged.</p>\n<h4 id=\"Number-of-active-600-and-total-1200-connections\"><a href=\"#Number-of-active-600-and-total-1200-connections\" class=\"headerlink\" title=\"Number of active (600) and total (1200) connections\"></a>Number of active (600) and total (1200) connections</h4><p>If you are developing a function requiring a lot of external resources, you can easily find yourself exhausting all available active connections. As each function can be ran multiple times (e.g. when it is triggered by a queue), as part of the same sandbox, the limit of 600 connections applies to all the instances combined.</p>\n<ul>\n<li>Best trick to avoid breaking the limit is having a single HttpClient instance and reusing it. It is thread safe and will spare you the need to constantly create and dispose of HttpClients, which is a bad practice overall. </li>\n<li>If multiple functions can reuse same external data, consider caching it in shared storage. </li>\n<li>Try to do as little work in a function as possible, as long running functions tend to exhaust connection limit more often.</li>\n</ul>\n<h4 id=\"Number-of-threads-512\"><a href=\"#Number-of-threads-512\" class=\"headerlink\" title=\"Number of threads (512)\"></a>Number of threads (512)</h4><p>If you are using System.Threading types to start threads manually, consider switching to Tasks, as they are able to utilize thread pool more efficiently. As a general advice, do not try to run many things in parallel, so avoid Threads, TPL and similar multithreaded libraries. It is better to have multiple smaller functions, than trying to handle everything in a single one.</p>\n<h4 id=\"Number-of-child-processes-32\"><a href=\"#Number-of-child-processes-32\" class=\"headerlink\" title=\"Number of child processes (32)\"></a>Number of child processes (32)</h4><p>Consider this limitation if your function has to spawn other processes. Too many child processes can also lead to increased memory usage, which directly affects billed costs of your Function App. In case Consumption Plan is not used, excessive process spawning can lead to underlying VM memory exhaustion.</p>\n<h3 id=\"Override-host-configuration-in-code\"><a href=\"#Override-host-configuration-in-code\" class=\"headerlink\" title=\"Override host configuration in code\"></a>Override host configuration in code</h3><p>If you notice parts of custom <em>host.json</em> configuration are ignored by FunctionApp, using default values instead, you might be running into the same issue I stumbled upon couple of times. Yet there is a way to ensure overriding host configuration, if you are running in-process application. <a href=\"https://github.com/Azure/azure-functions-servicebus-extension/issues/81#issuecomment-621431750]\">The solution</a> requires injecting dependencies using <em>FunctionStartup</em>, and is especially useful for changing extensions configuration.</p>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>Deep dive into Azure Functions originally started as another <a href=\"/categories/blog/ahaaas-august-2020/\">Ahaaas article</a>. As I have noticed there are more than five different points concerning functions, I decided to dig a bit deeper and bring you this text.</p>\n<p>In this article, I brought up ancient Azure history, in order to explain how Azure Functions came to be. Furthermore, I dissected most important function components and went through deploying and hosting options. Finally, I have included some of my personal experiences working with Azure Functions.</p>\n</body></html>",
            "tags": [
                "azure",
                "advanced"
            ]
        },
        {
            "id": "https://www.uveta.io/categories/blog/ahaaas-august-2020/",
            "url": "https://www.uveta.io/categories/blog/ahaaas-august-2020/",
            "title": "Ahaaas! - August 2020",
            "date_published": "2020-09-05T07:32:56.000Z",
            "content_html": "<html><head></head><body><img src=\"/categories/blog/ahaaas-august-2020/cartoon-1294877.png\" class=\"\" title=\"Eureka\">\n\n<p>New month, new exciting moments from my life as a developer. I hope you will enjoy reading about these flashes of clarity, that come suddenly after solving unfamiliar problems. Or as I like to call them - Ahaaas!</p>\n<span id=\"more\"></span>\n\n<h3 id=\"NET\"><a href=\"#NET\" class=\"headerlink\" title=\".NET\"></a>.NET</h3><ul>\n<li><p>Instead of using <code>BlockingCollection</code>, recommended implementation of producer/consumer pattern for .NET Core should utilize <a href=\"https://devblogs.microsoft.com/dotnet/an-introduction-to-system-threading-channels/\">Channels</a>. Besides granting full control of number of consumers, it is completely asynchronous and does not lead to thread blocking.</p>\n</li>\n<li><p>If writing a custom ASP.NET Core middleware, pay attention how scoped services are injected. As middlewares are registered as singletons, scoped services cannot be injected via constructor <a href=\"https://docs.microsoft.com/en-us/aspnet/core/fundamentals/middleware/write#middleware-dependencies\">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/middleware/write#middleware-dependencies</a>.</p>\n</li>\n<li><p>There is no simple way to resolve implementations of <code>IHostedService</code> or <code>BackgroundService</code> from DI container. Event though hosted services should not be injected into other services, if you absolutely need to, you can do one of the following (ordered by recommendation, from “yes, please” to “why would you do that”):</p>\n<ul>\n<li>Do not implement <code>IHostedService</code> directly, but create a hosted wrapper which injects your service and activates it on start; inject service elsewhere and not the hosted wrapper.</li>\n<li>Register service both as hosted service and a singleton; same instance will be resolved when injecting.</li>\n<li>Inject <code>IEnumerable&lt;IHostedService&gt;</code> and use LINQ to find instance by concrete type.</li>\n</ul>\n</li>\n<li><p>Use the following pattern if you require your event publisher to wait for asynchronous consumers. This can prove useful in case you are testing event driven units and require consumers to complete execution before code following publisher invocation continues. Another example is having application shutdown event, which could wait for consumers before exiting gracefully. Source code was obtained from <a href=\"https://stackoverflow.com/\">Stack Overflow</a> but for the life of me I could not find the original question again, hence no direct link :(</p>\n</li>\n</ul>\n<figure class=\"highlight cs hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">event</span> Func&lt;T, Task&gt; ItemQueued;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">async</span> Task <span class=\"hljs-title\">OnNewItemAsync</span>(<span class=\"hljs-params\">T item</span>)</span></span><br><span class=\"line\">{</span><br><span class=\"line\">    <span class=\"hljs-keyword\">if</span> (ItemQueued <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">null</span>) <span class=\"hljs-keyword\">return</span>;</span><br><span class=\"line\">    Func&lt;T, Task&gt; handler = ItemQueued;</span><br><span class=\"line\">    Delegate[] invocationList = handler.GetInvocationList();</span><br><span class=\"line\">    Task[] handlerTasks = <span class=\"hljs-keyword\">new</span> Task[invocationList.Length];</span><br><span class=\"line\">    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-built_in\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; invocationList.Length; i++)</span><br><span class=\"line\">    {</span><br><span class=\"line\">      handlerTasks[i] = ((Func&lt;T, Task&gt;)invocationList[i])(item);</span><br><span class=\"line\">    }</span><br><span class=\"line\">    <span class=\"hljs-keyword\">await</span> Task.WhenAll(handlerTasks);</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li><p>When developing server side Blazor application, HTML markup cannot be changed without having to rebuild the whole application. As this is something naturally supported by other SPA frameworks, you can achieve similar behaviour by running application with <em>dotnet watch run</em>. It will react to any change in source files, re-build and re-run application. It is not a perfect method in any way, but removes the need to manually stop, build and run every time.</p>\n</li>\n<li><p>If you use Visual Studio you can have <a href=\"https://chrissainty.com/get-some-sass-into-your-blazor-app/\">Sass in Blazor</a>! It can be achieved by installing an extension and including a specific NuGet package to projects with <em>.scss</em> files. In VS Code, you can use <a href=\"https://github.com/ritwickdey/vscode-live-sass-compiler\">Live Sass Compiler</a> extension.</p>\n</li>\n<li><p>Having trouble finding NuGet package storage and caches on your PC? Just use <em>dotnet nuget locals all –list</em> to show all relevant paths. Documentation about additional commands for managing NuGet sources can be found <a href=\"https://docs.microsoft.com/en-us/nuget/consume-packages/managing-the-global-packages-and-cache-folders\">here</a>.</p>\n</li>\n<li><p>Selective testing using <em>dotnet test --filter</em> argument <a href=\"https://docs.microsoft.com/en-us/dotnet/core/testing/selective-unit-tests?pivots=xunit\">https://docs.microsoft.com/en-us/dotnet/core/testing/selective-unit-tests?pivots=xunit</a>.</p>\n</li>\n<li><p>Even though health checks were introduced in ASP.NET Core 2.2, there are certain issues with initial implementation. Majority of them, mostly related to <code>IHealthCheckPublisher</code> host service and options, were fixed in version 3.0. But, if you are still using 2.2, you might want to check <a href=\"https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/health-checks?view=aspnetcore-2.2#health-check-publisher-1\">issue description and workarounds</a>.</p>\n</li>\n</ul>\n<h3 id=\"Azure\"><a href=\"#Azure\" class=\"headerlink\" title=\"Azure\"></a>Azure</h3><ul>\n<li><p>Even if you don’t think you’d need it, I recommend turning on soft delete on all blob storages, for at least a period of 7 days. It is one of few features that can protect you from accidental blob removal, as blob storage is currently not supported by Azure Backup. More details on how to enable this option can be found in <a href=\"https://docs.microsoft.com/en-us/azure/storage/blobs/soft-delete-enable\">official documentation</a>.</p>\n</li>\n<li><p>In order to test timer triggered Azure Functions, Portal can be used to manually invoke them. From the blade of your Function App, go to Functions, select specific function by name, go to Code + Test and click Test\\Run button. Function will be immediately invoked and you can even check its log output.</p>\n</li>\n<li><p>If you used official template to deploy Elasticsearch cluster to Azure, be sure to replace data disks on each node. They are deployed as standard HDD by default, but I would recommend using standard or, even better, premium SSD. The price difference is negligible, if you are not using very large disks. Obvious benefit is having query response time reduced by approximately 50%. To replace the disk, simply power down node VM, select data disk from Disks blade and switch it to SSD directly from Portal. Repeat for each node in your cluster.</p>\n</li>\n<li><p>When consuming Azure Service Bus queues/subscriptions, make sure MaxAutoRenewDuration is greater than LockDuration. As best practice, you should leave LockDuration to its default value of 1 minute, and set MaxAutoRenewDuration to maximum time it can take your consumer to process 1 message. If you want to learn more on how Service Bus consumers handle message locking, check <a href=\"https://stackoverflow.com/a/60381046\">this great answer on Stack Overflow</a>.</p>\n</li>\n</ul>\n<h3 id=\"Containers\"><a href=\"#Containers\" class=\"headerlink\" title=\"Containers\"></a>Containers</h3><ul>\n<li><p>Found a great online workshop showcasing Docker and Kubernetes for .NET developers <a href=\"https://dak4.net/\">https://dak4.net</a>.</p>\n</li>\n<li><p>Virtual Kubelet for Azure Container Instances does not support pod liveness, readiness or startup checks <a href=\"https://github.com/virtual-kubelet/azure-aci\">https://github.com/virtual-kubelet/azure-aci</a>. This can seriously limit its usage in production scenarios, as Kubernetes service will not be able to determine pod health. I recommend using ACI kubelet only for bursts of short-running operations. As a bonus piece of information, you can have only 100 ACI instances per subscription, which means virtual kubelet can handle maximum of 100 pods.</p>\n</li>\n<li><p>At the moment it is not possible to turn off performance monitoring for Azure Kubernetes Service. Collection of various logs can be tweaked, but performance telemetry cannot be configured in any way. This can result in not so small charges for data ingested in Log Analytics, especially if running lots of pods, as telemetry is gathered for every single one of them. Only option is to <a href=\"https://docs.microsoft.com/en-us/azure/azure-monitor/insights/container-insights-optout\">disable monitoring altogether</a>.</p>\n</li>\n</ul>\n<h3 id=\"Miscellaneous\"><a href=\"#Miscellaneous\" class=\"headerlink\" title=\"Miscellaneous\"></a>Miscellaneous</h3><ul>\n<li><p>Ever wished you could develop in emojis? Now you can <a href=\"https://www.emojicode.org/\">https://www.emojicode.org/</a>.</p>\n</li>\n<li><p>Great explanation of Linux filesystem and usage of various directories found in root path <a href=\"https://www.howtogeek.com/117435/htg-explains-the-linux-directory-structure-explained/\">https://www.howtogeek.com/117435/htg-explains-the-linux-directory-structure-explained/</a>. If you ever wondered what are /bin, /etc, /usr directories used for, look no further.</p>\n</li>\n<li><p>GitHub is launching its own <a href=\"https://github.blog/2020-09-01-introducing-github-container-registry/\">Container Registry</a>! At the moment, they are just missing their own Kubernetes offering to close development and deployment circle.</p>\n</li>\n</ul>\n</body></html>",
            "tags": [
                "azure",
                "advanced",
                ".net",
                "csharp",
                "containers"
            ]
        },
        {
            "id": "https://www.uveta.io/categories/blog/azure-solutions-architect-expert-part-2/",
            "url": "https://www.uveta.io/categories/blog/azure-solutions-architect-expert-part-2/",
            "title": "So you want to be an Azure Solutions Architect Expert - Part 2",
            "date_published": "2020-08-19T15:48:14.000Z",
            "content_html": "<html><head></head><body><img src=\"/categories/blog/azure-solutions-architect-expert-part-2/architect-badge.jpg\" class=\"\" title=\"Goal!!!\">\n\n<p>Microsoft Azure Architect Design is the second exam required for obtaining Azure Solutions Architect Expert certification. Backed up by deployment and configuration skills, obtained from preparation for Microsoft Azure Architect Technologies exam, we will tackle design of more complex and robust systems in this part.</p>\n<span id=\"more\"></span>\n\n<p>This post is part of my Azure Architect certification guide:</p>\n<ul>\n<li><a href=\"/categories/blog/azure-solutions-architect-expert-part-1\">So you want to be an Azure Solutions Architect Expert - Part 1</a></li>\n<li><a href=\"/categories/blog/azure-solutions-architect-expert-part-2\">So you want to be an Azure Solutions Architect Expert - Part 2</a> (this post)</li>\n</ul>\n<p><em>Disclaimer: on June 29, AZ-303 and AZ-304 were released, but only as beta for the time being. Exams being replaced, i.e. AZ-300 and AZ-301, will retire on September 30. I will take into account AZ-304 curriculum, and not dwell on AZ-301 topics that are becoming obsolete.</em></p>\n<h2 id=\"So-you-want-to-Solution-Architect-AZ-301-Microsoft-Azure-Architect-Design\"><a href=\"#So-you-want-to-Solution-Architect-AZ-301-Microsoft-Azure-Architect-Design\" class=\"headerlink\" title=\"So you want to Solution Architect (AZ-301: Microsoft Azure Architect Design)\"></a>So you want to Solution Architect (AZ-301: Microsoft Azure Architect Design)</h2><p><img src=\"az-301-badge.png\" alt=\"AZ-301: Microsoft Azure Architect Design\"></p>\n<p>Armed with knowledge of individual Azure services, design exam puts it all together under one roof. As a solution architect it will be your responsibility to create systems fulfilling both functional and non-functional requirements, while taking care not to overstep established restrictions. Desired reliability, availability, scalability and costs heavily influence your architecture and components used, hence a much deeper understanding of Azure services is required.</p>\n<h3 id=\"What-type-of-design-questions-await\"><a href=\"#What-type-of-design-questions-await\" class=\"headerlink\" title=\"What type of design questions await\"></a>What type of design questions await</h3><p>Question formats do not diverge much from the ones mentioned in <a href=\"/categories/blog/azure-solutions-architect-expert-part-1/#What-type-of-technology-questions-await\">previous post</a>. You should however expect many more case-studies, which best suit to illustrate obstacles confronted by a system designer.</p>\n<h3 id=\"Where-to-find-study-materials\"><a href=\"#Where-to-find-study-materials\" class=\"headerlink\" title=\"Where to find study materials\"></a>Where to find study materials</h3><p><img src=\"microsoft-docs-architecture.PNG\" alt=\"Microsoft Azure architecture documentation\"></p>\n<p>The same can be said for study materials. Microsoft documentation and video courses I previously suggested offer more than enough information needed to pass design exam as well. Special significance should be paid to <a href=\"https://docs.microsoft.com/en-us/azure/architecture/\">Azure architecture section</a>, containing reference architectures for different types of deployments. I suggest studying most commonly used ones by analyzing individual components and how they fit together to achieve desired system requirements.</p>\n<h3 id=\"Availability\"><a href=\"#Availability\" class=\"headerlink\" title=\"Availability\"></a>Availability</h3><p><img src=\"multi-region-web-app-diagram.png\" alt=\"App Service in multiple regions\"></p>\n<p>Understanding how Azure datacenters are organized on a global scale is imperative when planning for availability of your deployment. Although Microsoft offers generous SLA for all of its services, outages happen, and careful planning can help you mitigate such interruptions. Most important terms, covered by design exam, include:</p>\n<ul>\n<li>Datacenter. Basic building block of Azure, consisting of physical devices, storage, power and network connections.</li>\n<li>Availability zone. Collection of one or more datacenters with independent power and network connections. Most Azure resources can be distributed between different availability zones, helping against individual datacenter outages.</li>\n<li>Region. Specific location where Azure resources are deployed, guaranteeing compliance and data residency for specific state or country where datacenters are located. With regard to availability zones, each region contains at least 3 of them.</li>\n<li>Regional pair. Each Azure region is paired with another one, with prescribed minimum distance between them. This ensures resiliency in case of regional outages, due to natural disasters or any similar impediments. Any service update is rolled to one region per pair at a time. Also, in case of global Azure outage, Microsoft will prioritize restoring only one region per pair.</li>\n<li>Geography. Regions belonging to the same country are organized into geographies. Any regional pair is usually a part of the same geography, ensuring compliance and data residency. Exceptions do exists, especially for new geographies where usually only one region is deployed.</li>\n</ul>\n<p>Besides knowing how outage in any part of Azure infrastructure could affect you, it is vital to understand where each type of resources is deployed. While most of them are being deployed to specific regions, some of them, e.g. Traffic Manager, are non-regional and are deployed globally. Knowing which services allow distribution into availability zones, in order to handle datacenter outages, is also required.</p>\n<h3 id=\"Reliability\"><a href=\"#Reliability\" class=\"headerlink\" title=\"Reliability\"></a>Reliability</h3><p>When designing backup and recovery solution, it is imperative to take into account target Recovery Time Objectives (RTO) and Recovery Point Objectives (RPO). Simply put, they both impose requirements on how your system should behave in case of an outage. While RTO determines maximum period of time an outage is allowed to last, RPO specifies permitted amount of data loss during recovery. For critical system components these values would normally be expressed in seconds, while rarely used or obsolete parts could afford even daily outages. Values imposed by these requirements have great impact not only during recovery design, but also when optimizing costs, which I will cover in the following sections.</p>\n<p>To successfully conquer this part of the exam, deeper understanding of two services is required:</p>\n<ul>\n<li>Azure Backup. As the name implies, the service is used for managing backups of other services, be it Azure VM disks, on-premise file systems or SQL servers running on Azure VMs. Although you should be familiar with configuring and deploying it from technologies exam, understanding costs and data retention specifics will be required on design exam.</li>\n<li>Azure Site Recovery. This one is a complex hydra, since it can span multiple Azure regions and even handle on-premise systems connected via VPN. It heavily relies on Backup service and removes the need for manual intervention in case of a failure. I recommend spending some time trying out Site Recovery in Azure Portal, if you have a chance. How to identify failure (both infrastructure and application), how to recover to a secondary deployment (both Azure and on-premise) and how to minimize amount of lost data and downtime (RPO and RTO) are just some of the areas you will need to be proficient in. Luckily, Site Recovery allows manual failovers, allowing you to test and get a good grip on what can happen in case of a system failure.</li>\n</ul>\n<h3 id=\"Scalability\"><a href=\"#Scalability\" class=\"headerlink\" title=\"Scalability\"></a>Scalability</h3><p><img src=\"serverless-web-app.png\" alt=\"Scalable serverless application\"></p>\n<p>Most compute and database resources, offered by Azure, support scaling out of the box. The trick is knowing which service tier you have to use for specific resource type, as well how to effectively configure scaling to support increase of demand. Whether you are using VM scale sets or App Service, knowing how to configure auto-scaling rules and conditions is a must. Even services such as Function App, which inherently handle scaling, support further adjustments to it. This can be used to control burst of work and better handle costs of potentially unlimited compute resources.</p>\n<p>All previously mentioned areas (availability, reliability and scalability) represent pillars of any highly available and resilient deployment. I would once again emphasize the importance of <a href=\"https://docs.microsoft.com/en-us/azure/architecture/\">Azure architecture documentation</a>, which is an endless pool of reference architectures, allowing building systems fulfilling specific set of requirements.</p>\n<h3 id=\"Security\"><a href=\"#Security\" class=\"headerlink\" title=\"Security\"></a>Security</h3><p>As with any cloud environment, security is involved in almost all of Azure’s components and processes. For the purpose of design exam, I would divide security topics into following:</p>\n<ul>\n<li>User management, authentication and authorization. Beside knowing how to work with Azure AD and role-based access control (RBAC), which were covered in technologies exam, you will be expected to handle more advanced scenarios and options offered by Azure AD. Configuring single-sign on (SSO), multi-factor authentication (MFA) and dealing with hybrid identity using Azure AD Connect are just some of the examples. As you are expected to handle enterprise level deployments, automating and auditing certain tasks will be a necessity. Hence premium AD options such as Privileged Identity Management (PIM), self-service management, Identity Protection and Just In Time (JIT) VM access should not flow under your radar.</li>\n<li>Application security. Securing our compute resources comes in two flavours: handling service access to other Azure resources and protecting application data. While Managed Identity can handle service authentication, using service principals and RBAC, Azure Key Vault is usually used for storing sensitive application settings and certificates.</li>\n<li>Data protection. As our systems will deal with user data, it is imperative for all of its components to safeguard it. By designing a system that encrypts data at rest, in transit and while in use we can minimize the possibility and impact of data exposure. Knowing how different resources, based on their purpose, handle each part of data flow is a key to conquering these problems.</li>\n</ul>\n<h3 id=\"Cost-optimization\"><a href=\"#Cost-optimization\" class=\"headerlink\" title=\"Cost optimization\"></a>Cost optimization</h3><p>First step into providing good cost optimization is knowing when and how are you charged for using Azure resources. Although some costs are fixed, e.g each GB stored, VM reserved, certificate purchased and public IP address assigned, others are charged per usage unit, such as FunctionApp and Container Instances execution time, number of read/write requests to storage accounts and Cosmos DB request units, just to name a few. Different service tiers can also dramatically affect costs of entire deployment, due to extra features offered and more strict SLAs. No one will expect of you to provide exact price of deployment, but knowing how to reduce costs, while still adhering to requirements imposed, will be vital. </p>\n<p>In case of designing for reliability, you will mostly be faced with task of minimizing deployment cost, while maintaining specific RTO and RLO values. Knowing how each storage resource (Cosmos DB, blob and file storage) and recovery service (Site Recovery and Backup) handles these parameters is a skill you will have to master.</p>\n<h3 id=\"Governance-and-auditing\"><a href=\"#Governance-and-auditing\" class=\"headerlink\" title=\"Governance and auditing\"></a>Governance and auditing</h3><p>All parts of an enterprise must be compliant with pre-established rules, which does not exempt deployments made to Azure. Governance in Azure further includes creating and adhering completely new set of rules, specific for cloud environment. As an example, you could be tasked with designing resource tagging policy, in order to help identify business unit, application or employees responsible for specific resource or groups of resources.</p>\n<p>In order to ensure all deployed resources are compliant, Azure allows us to define policies for different scopes, i.e directory, subscription, resource group, etc. This goes even beyond deployments, as policy rules can be applied to user accounts, RBAC and other security entities governed by Azure AD. Azure Blueprints makes work with policies more straightforward, giving us possibility to define compliant resource templates ready for deployment. Blueprints go much further than simple ARM templates, as they are backed up by Cosmos DB, available to any user or group with access rights, and provide audit log upon deployment.</p>\n<h3 id=\"Miscellaneous\"><a href=\"#Miscellaneous\" class=\"headerlink\" title=\"Miscellaneous\"></a>Miscellaneous</h3><p>I will briefly cover further topics encountered during exam, that are not as extensive as previously mentioned ones.</p>\n<h4 id=\"Networking\"><a href=\"#Networking\" class=\"headerlink\" title=\"Networking\"></a>Networking</h4><p>Since virtual networks are ties that bind all other Azure resources, knowing how to design and utilize them is something that can not be overlooked. As they fall within the competence of Microsoft, you will have little influence over their operation and reliability. However, architect’s responsibility lay in other areas. Modeling addressing strategy for networks and sub-networks, connecting virtual networks and on-premise systems, directing network flow via routing and load balancers, as well as establishing security boundaries and rules are just some of the skills that will be expected of you on design exam.</p>\n<h4 id=\"Compute\"><a href=\"#Compute\" class=\"headerlink\" title=\"Compute\"></a>Compute</h4><p>Similar skills to ones required in technical exam are required, as choosing appropriate compute solution is still the main focus. There will however be additional requirements, requiring deeper knowledge of pricing tiers and respective offerings, total resource costs as well as scaling capabilities. Resource types covered by design exam are virtual machines, virtual machine scale sets, App Services, Service Fabric, Function Apps and containerized deployments. Regarding last one, make sure you understand difference between Azure Kubernetes Service and Azure Container Instances.</p>\n<h4 id=\"Archiving-and-data-retention\"><a href=\"#Archiving-and-data-retention\" class=\"headerlink\" title=\"Archiving and data retention\"></a>Archiving and data retention</h4><p>Storing not-frequently accessed data for auditing and compliance purposes is a necessity by today’s standards. Almost all Azure storage services include an archive tier, so you should be covered whether you are using Storage Accounts, Data Lake or Azure Backup, just to name a few. You would still need to know how to calculate the costs of archiving data, as well as special conditions for storing and accessing it.</p>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>In this post I described most important topics that are covered by AZ-301: Microsoft Azure Architect Design exam. Including previous post in the series, I have covered complete curriculum for Azure Solutions Architect Expert exam in its current form.</p>\n<p>If you would have any additional questions or remarks, I am eager to hear them in the comments bellow. If you are interested in future posts from Azure and .NET world, follow me on <a href=\"https://twitter.com/uveta\">Twitter</a> to get notified as soon as they get published.</p>\n</body></html>",
            "tags": [
                "azure",
                "certification",
                "advanced"
            ]
        },
        {
            "id": "https://www.uveta.io/categories/blog/ahaaas-july-2020/",
            "url": "https://www.uveta.io/categories/blog/ahaaas-july-2020/",
            "title": "Ahaaas! - July 2020",
            "date_published": "2020-07-25T17:12:39.000Z",
            "content_html": "<html><head></head><body><img src=\"/categories/blog/ahaaas-july-2020/bulb.png\" class=\"\" title=\"Eureka\">\n\n<p>In fast paced technology world, developers discover new insights practically on a daily level. Surely you have experienced these moments of almost divine wisdom, ending with “Now I know xyz can do that” or “I have to be aware of xyz” or “Eureka!”. I have recorded my moments of clarity, or Ahaaas as I call them, hoping that some of them will prove useful to you, whether you’d be dealing with .NET development, Azure or Docker.</p>\n<span id=\"more\"></span>\n\n<h3 id=\"NET\"><a href=\"#NET\" class=\"headerlink\" title=\".NET\"></a>.NET</h3><ul>\n<li>Mocking authentication in ASP.NET Core 3.0 integration tests <a href=\"https://docs.microsoft.com/en-us/aspnet/core/test/integration-tests#mock-authentication\">https://docs.microsoft.com/en-us/aspnet/core/test/integration-tests#mock-authentication</a></li>\n<li>Even though ASP.NET Core <code>IConfiguration</code> entry names are case-insensitive, <code>ConfigurationBinder.Bind()</code> method is not and property name casing does matter. Prefer using <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.optionsconfigurationservicecollectionextensions.configure\">Configure()</a> options extension method to bind configuration sections to option types.</li>\n<li>Be careful when using array values in <code>IConfiguration</code> data sources, especially if you consider overriding with environment specific configurations <a href=\"https://rimdev.io/avoiding-aspnet-core-configuration-pitfalls-with-array-values/\">https://rimdev.io/avoiding-aspnet-core-configuration-pitfalls-with-array-values/</a></li>\n<li>If you cannot rely on your reverse proxy, it is possible to add client and IP rate limiting to ASP.NET Core. Source code and installation instructions are available at <a href=\"https://github.com/stefanprodan/AspNetCoreRateLimit\">https://github.com/stefanprodan/AspNetCoreRateLimit</a>. Remember, however, that Kestrel should not be used as a public facing web server.</li>\n<li>Controller input model validation can be automated using <code>[ApiController]</code> attribute and annotations from <code>DataAnnotations</code> namespace <a href=\"https://docs.microsoft.com/en-us/aspnet/core/mvc/models/validation\">https://docs.microsoft.com/en-us/aspnet/core/mvc/models/validation</a></li>\n<li>When using <code>[DataMember]</code> attribute to annotate serialization model properties, do not forget to add <code>[DataContract]</code> to  enclosing type as well. Most of traditional JSON serializers, such as Newtonsoft and Jil, honor property attributes, but expect type to be annotated as well. <code>System.Text.Json.JsonSerializer</code> surprisingly does not utilize attributes from <code>System.Runtime.Serialization</code> namespace and uses its own <a href=\"https://docs.microsoft.com/en-us/dotnet/standard/serialization/system-text-json-how-to#customize-individual-property-names\">annotations</a></li>\n<li>Cool portability tool from .NET to .NET core comes from, you wouldn’t believe it, AWS team. More details <a href=\"https://aws.amazon.com/blogs/aws/announcing-the-porting-assistant-for-net/\">https://aws.amazon.com/blogs/aws/announcing-the-porting-assistant-for-net/</a></li>\n<li><code>System.Net.Mail.SmtpClient</code> is obsolete for some time; recommended alternative is <a href=\"https://github.com/jstedfast/MailKit\">MailKit</a></li>\n<li><code>IApplicationLifetime</code> service is obsolete from .Net Core 3.0. If you utilize generic host, use <code>IHostApplicationLifetime</code> instead <a href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.iapplicationlifetime\">https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.iapplicationlifetime</a></li>\n<li>Imagine you have a concrete type implementing two different interfaces. Now imagine you register this type for each interface as a singleton in DI container. When resolving each interface, you will end up with a different instances, i.e. .NET core DI container will create two instances instead of sharing single one.</li>\n<li>If you are looking for Blazor components that you can use for commercial projects, Syncfusion offers a handful via their community license <a href=\"https://www.syncfusion.com/products/communitylicense\">https://www.syncfusion.com/products/communitylicense</a></li>\n</ul>\n<h3 id=\"Azure\"><a href=\"#Azure\" class=\"headerlink\" title=\"Azure\"></a>Azure</h3><ul>\n<li>If you use sessions with Azure Service Bus, be sure to assign session identifier to messages before sending them. Service Bus will not complain if session is missing on enqueue, but will make hell for consumers on delivery and practically keep messages in queue and attempt to deliver them, until expired.</li>\n<li>You can use Azure Log Analytics to collect custom virtual machine logs <a href=\"https://docs.microsoft.com/en-us/azure/azure-monitor/platform/data-sources-custom-logs\">https://docs.microsoft.com/en-us/azure/azure-monitor/platform/data-sources-custom-logs</a>. In Portal, open your  Log Analytics workspace and go to Advanced Settings-&gt;Data-&gt;Custom Logs. You can also collect Windows Event and IIS Logs, as well as Linux Syslog, in a similar fashion.</li>\n<li>Data sampling, configured in Application Insight’s Usage and Estimated Costs, has no effect if you are using ASP.NET core applications without modifying telemetry sampling configuration. Ingested data can significantly increase costs, especially if Azure Functions are used, so use Daily Cap setting to get notified if the amount ingested passes the limit.</li>\n<li>Microsoft Q&amp;A is generally available and should help you find any technical information regarding Azure services <a href=\"https://docs.microsoft.com/en-us/answers/products/\">https://docs.microsoft.com/en-us/answers/products/</a></li>\n</ul>\n<h3 id=\"Miscellaneous\"><a href=\"#Miscellaneous\" class=\"headerlink\" title=\"Miscellaneous\"></a>Miscellaneous</h3><ul>\n<li>Nice overview of most commonly used open source licenses, with usage restrictions <a href=\"https://choosealicense.com/\">https://choosealicense.com</a></li>\n<li>Steve Dunn used Blazor to recreate original Pacman <a href=\"http://pacmanblazor.azurewebsites.net/\">http://pacmanblazor.azurewebsites.net</a>. With a little bit of JS interop, he was able to demonstrate potential of client-side Blazor running on WebAssembly. Source code can be found on <a href=\"https://github.com/SteveDunn/PacManBlazor\">Github</a></li>\n<li>Postman automatically converts POST requests if it receives a 301 redirect status code. In this situation, it drops any request content and issues a GET request to redirecting location without any body data. This can lead to trouble, as user is never notified of such change during request execution. To avoid such issues, better turn off automatic redirects in Postman settings.</li>\n<li>Elasticsearch .NET client version 7.1.0 seems to have issues when running on .NET core 3.0. Updating client to latest version (7.8.0 at the moment of writing) seems to help.</li>\n</ul>\n</body></html>",
            "tags": [
                "azure",
                "advanced",
                ".net",
                "csharp",
                "containers"
            ]
        },
        {
            "id": "https://www.uveta.io/categories/blog/azure-solutions-architect-expert-part-1/",
            "url": "https://www.uveta.io/categories/blog/azure-solutions-architect-expert-part-1/",
            "title": "So you want to be an Azure Solutions Architect Expert - Part 1",
            "date_published": "2020-06-26T15:48:14.000Z",
            "content_html": "<html><head></head><body><img src=\"/categories/blog/azure-solutions-architect-expert-part-1/architect-badge.jpg\" class=\"\" title=\"Goal!!!\">\n\n<p>This post is intended for anyone actively trying to, or considering, obtaining Azure Solutions Architect Expert certification. As I have obtained certificate near the end of 2019, I wanted to share relevant information and findings gathered prior to and after taking exams, in order to help future applicants.</p>\n<span id=\"more\"></span>\n<p>This post is part of my Azure Architect certification guide:</p>\n<ul>\n<li><a href=\"/categories/blog/azure-solutions-architect-expert-part-1\">So you want to be an Azure Solutions Architect Expert - Part 1</a> (this post)</li>\n<li><a href=\"/categories/blog/azure-solutions-architect-expert-part-2\">So you want to be an Azure Solutions Architect Expert - Part 2</a></li>\n</ul>\n<p><em>Disclaimer: as AZ-300 and AZ-301 are being replaced with AZ-303 and AZ-304 exams late June 2020, you might find some information provided in this post to be outdated. I will try to take into account all information available for future versions and not go into details about topics that are becoming obsolete.</em></p>\n<h2 id=\"Prerequisites\"><a href=\"#Prerequisites\" class=\"headerlink\" title=\"Prerequisites\"></a>Prerequisites</h2><p>In order to qualify for Azure Solutions Architect Expert certification, you are required to pass two exams: AZ-300: Microsoft Azure Architect Technologies and AZ-301: Microsoft Azure Architect Design. While AZ-300 deals mostly with skills related to deploying and configuring individual services to Azure, AZ-301 takes a deep dive into fulfilling business and system requirements such as availability, reliability, performance, as well as optimizing costs. I will focus mostly on technical aspects and go briefly through the types of questions you would encounter. Organizational information, such as exam length, scoring and how to apply, will not be a part of this post. Such instructions can be obtained from <a href=\"https://docs.microsoft.com/en-us/learn/certifications/azure-solutions-architect\">Microsoft certification site</a></p>\n<h2 id=\"Where-to-find-study-materials\"><a href=\"#Where-to-find-study-materials\" class=\"headerlink\" title=\"Where to find study materials\"></a>Where to find study materials</h2><p><img src=\"microsoft-learn.png\" alt=\"Your new best friend\"></p>\n<p>Answer to this question is very simple: <a href=\"https://docs.microsoft.com/\">Microsoft Docs</a> has all the information you will ever need to prepare for this certification. The only problem is there a lot of it. Like, really a lot. Like, it would take you several lifetimes to only skim it through. Not to mention content is added to it on a daily basis. Still, official Microsoft documentation is the ultimate place where you will find answers to any question about Azure. It is also pretty easy to navigate and search for relevant information. If you have not worked with it already, take some time to familiarize yourself. Because you will be coming back to it regularly.</p>\n<p>Nick Colyer’s courses offered by <a href=\"https://courses.skylinesacademy.com/p/az-300-301\">Skylines Academy</a> helped me identify all relevant topics required for the exams. Both of them clock at about 20 hours in total, which could be covered in a single weekend, if you are persistent enough. The course aided me getting into meat and bones of each exam and understanding what is required to pass. I cannot recommend it enough, as the course should serve you as a starting point into further studying. As a bonus piece of information, both courses are also available on <a href=\"https://acloud.guru/azure-cloud-training\">A Cloud Guru</a>, which offers seven day free trial.</p>\n<p>On the other hand, Pluralsight has great paths for both <a href=\"https://www.pluralsight.com/paths/microsoft-azure-architect-technologies-az-300\">AZ-300</a> and <a href=\"https://www.pluralsight.com/paths/microsoft-azure-architect-design-az-301\">AZ-301</a> exam. Each path consists of dozen courses going into great depths of each topic covered. What I consider its greatest obstacle is the sheer amount of material, as both paths have, in total, well over 150 hours of video content. I would recommend them only to applicants who have enough time to spare. If you are not one of them, try to go through the materials at increased speed (1.2x or 1.3x works fine) or at least use them to selectively strengthen knowledge in areas you find yourself lacking. Pluralsight comes with a 10 day free trial, or, if you are lucky to have Visual Studio subscription, 3 to 6 months trial.</p>\n<p>Lastly, try to go through a couple of practice tests, especially if you have never participated in this kind of exam. Some of them are offered on <a href=\"https://docs.microsoft.com/en-us/learn/certifications/azure-solutions-architect\">Certification page</a>. Also, both <a href=\"https://www.udemy.com/course/azure-architect-technologies-practice-tests-az-300-az-303\">AZ-300/AZ-303</a> and <a href=\"https://www.udemy.com/course/az-301-azure-architect-design-practice-test\">AZ-301/AZ-304</a> packs can be found on Udemy.</p>\n<h2 id=\"So-you-want-to-Azure-AZ-300-Microsoft-Azure-Architect-Technologies\"><a href=\"#So-you-want-to-Azure-AZ-300-Microsoft-Azure-Architect-Technologies\" class=\"headerlink\" title=\"So you want to Azure (AZ-300: Microsoft Azure Architect Technologies)\"></a>So you want to Azure (AZ-300: Microsoft Azure Architect Technologies)</h2><p><img src=\"az-300-badge.jpg\" alt=\"AZ-300: Microsoft Azure Architect Technologies\"></p>\n<p>With basic information out of the way, it is time to plunge ourselves into technical skills required. Exam marked as AZ-300 will put your knowledge of Azure services, deployment, configuration and networking to test.</p>\n<h3 id=\"What-type-of-technology-questions-await\"><a href=\"#What-type-of-technology-questions-await\" class=\"headerlink\" title=\"What type of technology questions await\"></a>What type of technology questions await</h3><p>Technologies exam is a mixed bag of all <a href=\"https://www.microsoft.com/en-us/learning/certification-exams.aspx\">question types</a> that Microsoft is currently using. Best answer, multiple choice, drag and drop and case studies are just some of the formats you can expect.</p>\n<p>Beware, significant part of AZ-300 are also hands-on tasks done directly in simulated Azure portal. They usually involve deploying and configuring several resources according to specification. For this reason, you really need to be comfortable working with portal using GUI as well as CLI or Powershell. Read the tasks at hand thoroughly and understand what is required of you, as speed is of essence here. From my personal experience, this part of exam took nearly half of available time, which I only realized once I was finished with it. Try not to repeat my mistake.</p>\n<h3 id=\"Storage-resources\"><a href=\"#Storage-resources\" class=\"headerlink\" title=\"Storage resources\"></a>Storage resources</h3><p>Working with different types of persistence technologies is pretty straightforward, since Azure hides most of the infrastructure details and leaves us with a pretty well-established abstractions. Although each of them can be used in multiple ways, there is usually an obvious best choice fulfilling task requirements. Typical concerns regarding service options are as follows:</p>\n<ul>\n<li>Storage account. Bread-and-butter of all persistence technologies, it is used by almost all Azure services requiring storage, even without users being aware of it. As a solution architect, you are expected to know what kind of services it offers (blob, file, queue, table) as well as difference between historical versions, e.g. Gen1 and Gen2, since even obsolete ones are still being offered. For each individual service, you should understand various options offered during deployment and how do they impact created resource.</li>\n<li>CosmosDB. At the time of AZ-300 creation CosmosDB was still new kid on the block, hence most database related questions involved different types of SQL Server and DocumentDB deployments. This is changing in AZ-303, since CosmosDB is heavily featured in its curriculum as a de facto NoSQL standard in Azure. Make sure you are familiar with different application interfaces it offers and how to optimize usage based on functional requirements. Same goes for Azure SQL database, in case relational database solution is required.</li>\n<li>Azure Service Bus. Although not typically used for storage, it still offers persistence in certain scenarios. You should be aware how Service Bus is utilized as a messaging medium, and what sets it appart from services such as Event Grid and Azure Queue storage. Make sure you understand difference between queue, consumer, topic and subscribers, and when each one should be utilized.</li>\n<li>Data lake and Azure Files. These services have specific usage scenarios which you need to be aware of. While Data Lake plays a pivotal role in storing and processing extreme ammounts of data, Azure files are especially prominent in backup and migration solutions.</li>\n</ul>\n<h3 id=\"Network-and-connectivity\"><a href=\"#Network-and-connectivity\" class=\"headerlink\" title=\"Network and connectivity\"></a>Network and connectivity</h3><p>Networking area is pretty straightforward, as it follows a set of explicit rules with little space to be creative. But do not even attempt to dive into it if you have knowledge gaps in topics such as IP addresses, CIDR notation, subnets, public and private ranges or what DNS is and how it works. All of these are just basis for whats to come, so make sure you handle them well first.</p>\n<p>Exam specific topics include, but are not limited to:</p>\n<ul>\n<li>Virtual Networks (VNETs). Learn how to plan, deploy and configure them, how to use subnets effectively, what type of resources can be deployed to virtual network and what are the limitations.</li>\n<li>Connectivity. Find out what are the options when establishing connection between VNETs, on-premise locations and individual remote peers. Any combination is plausible, sometimes even all of them, and you need to know what kind of service is adequate for given scenario. Spend some time learning about VNET peering, ExpressRoute and VPN gateway.</li>\n<li>Routing and load balancing. Although not heavily emphasized in this exam, knowledge of different network appliances is still needed. Make sure you know what is the purpose of load balancer, custom appliances, Application Gateway, Traffic Manager and Azure Front Door, as well as basic deployment and configuration steps.</li>\n<li>Security. An important topic that can easily slip you by. You need to understand default security rules for resources deployed to VNETs and how to adjust them further. Do not miss reading on Network Security Groups (NSG), how to define individual security rules and where NSGs can be applied. Also, recognize what type of threats Web Application Firewall can protect your resources from and how to deploy it.</li>\n<li>DNS. Understand various Azure DNS service offerings. Make sure you know the difference between CNAME and A record and how they are used to perform different tasks in Azure. Examples include overriding default assigned server names or exposing deployed Azure services under your specific domain.</li>\n</ul>\n<h3 id=\"Compute-resources\"><a href=\"#Compute-resources\" class=\"headerlink\" title=\"Compute resources\"></a>Compute resources</h3><p><img src=\"compute-decision-tree.jpg\" alt=\"Compute service decision tree\"></p>\n<p>Realizing difference between service models offered by Azure is the key knowledge working with compute resources. Because all of them, in the end, have single purpose: to run a piece of code or application in cloud environment. Although there are many characteristics that will come into play in the design part, main point that you should take away for technology exam is the level of responsibility you have towards individual compute resources. Good overview of all Azure offerings is required as well, so make sure terms like Virtual Machines, App Service, Azure Functions and Kubernetes Service do not fall under your radar. Deploying and configuring all of them will be required of you, especially in the hands-on part of the exam.</p>\n<p>Note that, even though Service Fabric was part of AZ-300 curriculum, it is missing from AZ-303.</p>\n<h3 id=\"Monitoring-solutions\"><a href=\"#Monitoring-solutions\" class=\"headerlink\" title=\"Monitoring solutions\"></a>Monitoring solutions</h3><p>Tasks related to monitoring resources do not necessarily include only tools used to track performance and functionality of your deployment. Analytic services can help you optimize resource usage in order to provide more robust, flexible and often cheaper deploymen. Although complete monitoring solution often involves combination of several services, basic building blocks are:</p>\n<ul>\n<li>Log Analytics. Used to persist all log information. All services to follow utilize it either to store or read required data. Kusto language is used to query Log Analytics tables, but knowledge about its usage and syntax are no longer needed, as it was removed from AZ-303 curriculum.</li>\n<li>Azure Monitor. Fundamental service used to track various metrics gathered from underlying virtual machines. Although it is not deployed manually, ability to read Monitor metrics and define actions based on them will be expected of you.</li>\n<li>Application Insights. Often correlated with advanced compute resources, such as App Service and Azure Functions. How to track application metrics, logs and usage statistics is required knowledge for the exam.</li>\n<li>Action groups and Alerts. Although they represent separate entities in Azure, these two come hand in hand when developing notification solution. Double-check you are able to create alerts based on Azure resource metrics and notify appropriate targets.</li>\n<li>Azure Advisor. Even if you create advanced monitoring solution for your infrastructure and applications, covering wide range of system requirements, certain issues can slip under your radar. Azure Advisor can detect some of these automatically. It analyzes security, performance, reliability as well as cost of your deployment, and often helps optimize it based on preestablished rules. The exam will expect you to know basic issues that Azure advisor can help you solve.</li>\n</ul>\n<h3 id=\"Backup-and-migration\"><a href=\"#Backup-and-migration\" class=\"headerlink\" title=\"Backup and migration\"></a>Backup and migration</h3><p>A significant part of the curriculum is dedicated to migration from on-premise site to cloud environment, hence learning about available tools and how to utilize them is pretty much a necessity. Azure Migrate is a versatile service covering everything from analyzing on-site resource utilization, provisioning cloud counterparts and even executing planned migrations. Learning about its individual components and their specifics is the key to get by this part of the exam.</p>\n<p>On the other side, most notable backup services are covered by Azure Backup and Site Recovery. Since they play pivotal role in strengthening deployment resiliency and availability, they will be further mention during design exam post. For technological part, knowing how to deploy and configure them will suffice.</p>\n<h3 id=\"Security-components\"><a href=\"#Security-components\" class=\"headerlink\" title=\"Security components\"></a>Security components</h3><p>Since we mentioned security several times till now, it goes without saying it plays huge role in cloud environment. Azure is no different and offers you tools to finely adjust every part of your solution.</p>\n<p>Heart of security is Azure AD, which is utilized in every aspect requiring authentication or authorization. Whether your solution is deployed purely to cloud, or you wish to combine it with on-premise resources, Azure has appropriate offering for you. Verify what the desired scenario is and know what kind of deployment is suitable.</p>\n<p>Abbreviations such as RBAC, MFA, OAuth, OpenID and SAS must mean something to you. You have to be able to control and monitor user access to Azure resources and utilize advanced options offered by premium licenses. Know how to use Managed Identity and Security Principals to control service access to Azure resources. Learn how Key Vault can help store sensitive data and how to utilize it.</p>\n<h3 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h3><p>If you go back and read previous sections, the most frequent word used would probably be deployment. Since it plays a mayor role even before you start working with resources in Azure, it deserves an honorary mention.</p>\n<p>Azure Resource Manager templates, or simply ARM, is a term you will most definitely encounter when dealing with resource deployments. Understanding basic structure of ARM and how to export, as well as adjust them, will be expected of you. They can immensely help you during hands-on parts as well, especially if multiple resource deployment is required.</p>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>In this post I went through Azure Solutions Architect Expert certification prerequisites and recommended learning strategy. I have also covered most significant topics that you can encounter during first certification exam.</p>\n<p>In the next post I will go through skills and knowledge required for the second exam, i.e. AZ-301: Microsoft Azure Architect Design. Follow me on <a href=\"https://twitter.com/uveta\">Twitter</a> to get notified when it gets published.</p>\n</body></html>",
            "tags": [
                "azure",
                "certification",
                "advanced"
            ]
        }
    ]
}